{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PlUmXGnjI-1c",
        "outputId": "c20f1760-97cc-471c-b0a0-b43b7d6e1c07"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 2465 lines of sonnets\n",
            "\n",
            "The first 5 lines look like this:\n",
            "\n",
            "from fairest creatures we desire increase,\n",
            "that thereby beauty's rose might never die,\n",
            "but as the riper should by time decease,\n",
            "his tender heir might bear his memory:\n",
            "but thou contracted to thine own bright eyes,\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import pickle\n",
        "\n",
        "\n",
        "\n",
        "FILE_PATH = 'sonnets1.txt'\n",
        "NUM_BATCHES = 16\n",
        "LSTM_UNITS = 128\n",
        "EMBEDDING_DIM = 100\n",
        "\n",
        "\n",
        "# Read the data\n",
        "with open(FILE_PATH) as f:\n",
        "    data = f.read()\n",
        "\n",
        "# Convert to lower case and save as a list\n",
        "corpus = data.lower().split(\"\\n\")\n",
        "\n",
        "print(f\"There are {len(corpus)} lines of sonnets\\n\")\n",
        "print(f\"The first 5 lines look like this:\\n\")\n",
        "for i in range(5):\n",
        "  print(corpus[i])\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def fit_vectorizer(corpus):\n",
        "    \"\"\"\n",
        "    Instantiates the vectorizer class on the corpus\n",
        "\n",
        "    Args:\n",
        "        corpus (list): List with the sentences.\n",
        "\n",
        "    Returns:\n",
        "        (tf.keras.layers.TextVectorization): an instance of the TextVectorization class containing the word-index dictionary, adapted to the corpus sentences.\n",
        "    \"\"\"\n",
        "\n",
        "    tf.keras.utils.set_random_seed(65) # Do not change this line or you may have different expected outputs throughout the assignment\n",
        "\n",
        "    ### START CODE HERE ###\n",
        "\n",
        "     # Define the object with appropriate parameters\n",
        "    vectorizer = tf.keras.layers.TextVectorization(\n",
        "        standardize='lower_and_strip_punctuation',  # Convert to lowercase and strip punctuation\n",
        "        split='whitespace',  # Split on whitespace (default)\n",
        "        ragged=True,  # Allow ragged tensors\n",
        "        output_mode='int'  # Output as integers\n",
        "    )\n",
        "\n",
        "    # Adapt it to the corpus\n",
        "    vectorizer.adapt(corpus)\n",
        "    ### END CODE HERE ###\n",
        "\n",
        "    return vectorizer"
      ],
      "metadata": {
        "id": "YcCKj47BJSsf"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer = fit_vectorizer(corpus)\n",
        "total_words = len(vectorizer.get_vocabulary())\n",
        "print('Name: PRAVIN RAJ A     Register Number: 212222240079               ')\n",
        "print(f\"Total number of words in corpus (including the out of vocabulary): {total_words}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vj2s_TreJWBQ",
        "outputId": "9ab4150d-e239-4212-871b-f697a94bac00"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: PRAVIN RAJ A     Register Number: 212222240079               \n",
            "Total number of words in corpus (including the out of vocabulary): 3180\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Name:PRAVIN RAJ A      Register Number: 212222240079                ')\n",
        "print(f\"Passing a string directly: {vectorizer('This is a test string').__repr__()}\")\n",
        "print(f\"Passing a list of strings: {vectorizer(['This is a test string'])}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aBbQAuv0Jcqp",
        "outputId": "38b85fd8-7c4b-4a00-8088-d7f41e461a42"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name:PRAVIN RAJ A      Register Number: 212222240079                \n",
            "Passing a string directly: <tf.Tensor: shape=(5,), dtype=int64, numpy=array([  30,   14,   18,    1, 1688])>\n",
            "Passing a list of strings: <tf.RaggedTensor [[30, 14, 18, 1, 1688]]>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def n_gram_seqs(corpus, vectorizer):\n",
        "    \"\"\"\n",
        "    Generates a list of n-gram sequences\n",
        "\n",
        "    Args:\n",
        "        corpus (list of string): lines of texts to generate n-grams for\n",
        "        vectorizer (tf.keras.layers.TextVectorization): an instance of the TextVectorization class adapted in the corpus\n",
        "\n",
        "    Returns:\n",
        "        (list of tf.int64 tensors): the n-gram sequences for each line in the corpus\n",
        "    \"\"\"\n",
        "    input_sequences = []\n",
        "\n",
        "    ### START CODE HERE ###\n",
        "    for sentence in corpus:\n",
        "        # Vectorize the sentence to get the token indices\n",
        "        vectorized_sentence = vectorizer(sentence)\n",
        "\n",
        "        # Generate n-grams for the vectorized sentence\n",
        "        for i in range(2, vectorized_sentence.shape[0] + 1):  # Start from 2 to avoid the first token\n",
        "            n_gram = vectorized_sentence[:i]\n",
        "            input_sequences.append(n_gram)\n",
        "\n",
        "    ### END CODE HERE ###\n",
        "\n",
        "    return input_sequences\n",
        ""
      ],
      "metadata": {
        "id": "ntqdjclDJjqa"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply the n_gram_seqs transformation to the whole corpus\n",
        "input_sequences = n_gram_seqs(corpus, vectorizer)\n",
        "\n",
        "# Save max length\n",
        "max_sequence_len = max([len(x) for x in input_sequences])\n",
        "print('Name:PRAVIN RAJ A      Register Number: 212222240079                ')\n",
        "print(f\"n_grams of input_sequences have length: {len(input_sequences)}\")\n",
        "print(f\"maximum length of sequences is: {max_sequence_len}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UZqPAb3vJntU",
        "outputId": "673f2e05-3227-4d64-e7f8-353190e70076"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name:PRAVIN RAJ A      Register Number: 212222240079                \n",
            "n_grams of input_sequences have length: 15428\n",
            "maximum length of sequences is: 11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# GRADED FUNCTION: pad_seqs\n",
        "\n",
        "def pad_seqs(input_sequences, max_sequence_len):\n",
        "    \"\"\"\n",
        "    Pads tokenized sequences to the same length\n",
        "\n",
        "    Args:\n",
        "        input_sequences (list of int): tokenized sequences to pad\n",
        "        maxlen (int): maximum length of the token sequences\n",
        "\n",
        "    Returns:\n",
        "        (np.array of int32): tokenized sequences padded to the same length\n",
        "    \"\"\"\n",
        "\n",
        "   ### START CODE HERE ###\n",
        "    # Convert tensors to lists if necessary\n",
        "    input_list = [seq if isinstance(seq, list) else seq.numpy().tolist() for seq in input_sequences]\n",
        "\n",
        "    # Use pad_sequences to pad the sequences with left padding ('pre')\n",
        "    padded_sequences = tf.keras.preprocessing.sequence.pad_sequences(\n",
        "        input_list,              # Use the list of lists for padding\n",
        "        maxlen=max_sequence_len,  # Set the maximum length\n",
        "        padding='pre',            # Pad sequences to the left (before the sequence)\n",
        "        dtype='int32'             # Specify the output type as int32\n",
        "    )\n",
        "    ### END CODE HERE ###\n",
        "\n",
        "    return padded_sequences"
      ],
      "metadata": {
        "id": "XWvbt9zKJ6N-"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pad the whole corpus\n",
        "input_sequences = pad_seqs(input_sequences, max_sequence_len)\n",
        "print('Name:PRAVIN RAJ A      Register Number: 212222240079                ')\n",
        "print(f\"padded corpus has shape: {input_sequences.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mQw7Ae6JJ9oM",
        "outputId": "d5516858-3e71-4cce-e7c7-4f88a480e563"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name:PRAVIN RAJ A      Register Number: 212222240079                \n",
            "padded corpus has shape: (15428, 11)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# GRADED FUNCTION: features_and_labels\n",
        "\n",
        "def features_and_labels_dataset(input_sequences, total_words):\n",
        "    \"\"\"\n",
        "    Generates features and labels from n-grams and returns a tensorflow dataset\n",
        "\n",
        "    Args:\n",
        "        input_sequences (list of int): sequences to split features and labels from\n",
        "        total_words (int): vocabulary size\n",
        "\n",
        "    Returns:\n",
        "        (tf.data.Dataset): Dataset with elements in the form (sentence, label)\n",
        "    \"\"\"\n",
        "    ### START CODE HERE ###\n",
        "    # Define the features by taking all tokens except the last one for each sequence\n",
        "    features = [seq[:-1] for seq in input_sequences]\n",
        "\n",
        "    # Define the labels by taking the last token for each sequence\n",
        "    labels = [seq[-1] for seq in input_sequences]\n",
        "\n",
        "    # One-hot encode the labels using total_words as the number of classes\n",
        "    one_hot_labels = tf.keras.utils.to_categorical(labels, num_classes=total_words)\n",
        "\n",
        "    # Build the dataset using the features and one-hot encoded labels\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((features, one_hot_labels))\n",
        "\n",
        "    # Batch the dataset with a batch size of 16\n",
        "    batch_size = 16  # Feel free to adjust this based on the global variable, but should be <= 64\n",
        "    batched_dataset = dataset.batch(batch_size)\n",
        "\n",
        "    ### END CODE HERE ###\n",
        "\n",
        "    return batched_dataset\n",
        "\n",
        "\n",
        "# Split the whole corpus\n",
        "dataset = features_and_labels_dataset(input_sequences, total_words).prefetch(tf.data.AUTOTUNE)\n",
        "print('Name:PRAVIN RAJ A      Register Number: 212222240079                ')\n",
        "print(f\"Feature shape: {dataset.element_spec[0]}\")\n",
        "print(f\"Label shape: {dataset.element_spec[1]}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PiT_hm6dKCeo",
        "outputId": "f8396fa2-e430-41ce-c491-f727c5f00fd7"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name:PRAVIN RAJ A      Register Number: 212222240079                \n",
            "Feature shape: TensorSpec(shape=(None, 10), dtype=tf.int32, name=None)\n",
            "Label shape: TensorSpec(shape=(None, 3180), dtype=tf.float64, name=None)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# GRADED FUNCTION: create_model\n",
        "\n",
        "def create_model(total_words, max_sequence_len):\n",
        "    \"\"\"\n",
        "    Creates a text generator model\n",
        "\n",
        "    Args:\n",
        "        total_words (int): size of the vocabulary for the Embedding layer input\n",
        "        max_sequence_len (int): length of the input sequences\n",
        "\n",
        "    Returns:\n",
        "       (tf.keras Model): the text generator model\n",
        "    \"\"\"\n",
        "    model = tf.keras.Sequential()\n",
        "\n",
        "   ### START CODE HERE ###\n",
        "    # Input layer shape is max_sequence_len - 1 because we removed the last word as a label\n",
        "    model.add(tf.keras.layers.Input(shape=(max_sequence_len - 1,)))\n",
        "\n",
        "    # Embedding layer\n",
        "    model.add(tf.keras.layers.Embedding(input_dim=total_words,\n",
        "                                        output_dim=100,\n",
        "                                        input_length=max_sequence_len - 1))\n",
        "\n",
        "    # Add a Bidirectional LSTM layer with 150 units\n",
        "    model.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(150)))\n",
        "\n",
        "    # Add a Dense layer with 'total_words' units and softmax activation\n",
        "    model.add(tf.keras.layers.Dense(total_words, activation='softmax'))\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(loss='categorical_crossentropy',\n",
        "                  optimizer='adam',\n",
        "                  metrics=['accuracy'])\n",
        "    ### END CODE HERE ###\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "model = create_model(total_words, max_sequence_len)\n",
        "\n",
        "\n",
        "example_batch = dataset.take(1)\n",
        "\n",
        "try:\n",
        "\tmodel.evaluate(example_batch, verbose=False)\n",
        "except:\n",
        "\tprint(\"Your model is not compatible with the dataset you defined earlier. Check that the loss function and last layer are compatible with one another.\")\n",
        "else:\n",
        "\tpredictions = model.predict(example_batch, verbose=False)\n",
        "\tprint(f\"predictions have shape: {predictions.shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g3fNRxcrKUZn",
        "outputId": "a8baa79a-ffaf-41db-9e6c-903eb6455494"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "predictions have shape: (16, 3180)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(dataset, epochs=30, verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iveNzKGCKaLV",
        "outputId": "c7b72502-082a-4864-94af-ea38cb2188f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m965/965\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 55ms/step - accuracy: 0.0277 - loss: 7.0351\n",
            "Epoch 2/30\n",
            "\u001b[1m965/965\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 50ms/step - accuracy: 0.0323 - loss: 6.1059\n",
            "Epoch 3/30\n",
            "\u001b[1m965/965\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 56ms/step - accuracy: 0.0441 - loss: 5.7217\n",
            "Epoch 4/30\n",
            "\u001b[1m965/965\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 50ms/step - accuracy: 0.0521 - loss: 5.3645\n",
            "Epoch 5/30\n",
            "\u001b[1m965/965\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 49ms/step - accuracy: 0.0642 - loss: 5.0802\n",
            "Epoch 6/30\n",
            "\u001b[1m295/965\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m34s\u001b[0m 51ms/step - accuracy: 0.0720 - loss: 4.9264"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get training and validation accuracies\n",
        "acc = history.history['accuracy']\n",
        "loss = history.history['loss']\n",
        "\n",
        "# Get number of epochs\n",
        "epochs = range(len(acc))\n",
        "\n",
        "fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
        "fig.suptitle('Training performance - Accuracy and Loss / Name:ROSELIN     Register Number:212222230122        ')\n",
        "\n",
        "for i, (data, label) in enumerate(zip([acc,loss], [\"Accuracy\", \"Loss\"])):\n",
        "    ax[i].plot(epochs, data, label=label)\n",
        "    ax[i].legend()\n",
        "    ax[i].set_xlabel('epochs')\n",
        "\n"
      ],
      "metadata": {
        "id": "gc1aCazRKeZi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('history.pkl', 'wb') as f:\n",
        "    pickle.dump(history.history, f)"
      ],
      "metadata": {
        "id": "HmP0B4dNKh5Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seed_text = \"Help me Obi Wan Kenobi, you're my only hope\"\n",
        "next_words = 100\n",
        "\n",
        "for _ in range(next_words):\n",
        "    # Convert the text into sequences\n",
        "    token_list = vectorizer(seed_text)\n",
        "    # Pad the sequences\n",
        "    token_list = tf.keras.utils.pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
        "    # Get the probabilities of predicting a word\n",
        "    predicted = model.predict([token_list], verbose=0)\n",
        "    # Choose the next word based on the maximum probability\n",
        "    predicted = np.argmax(predicted, axis=-1).item()\n",
        "    # Get the actual word from the word index\n",
        "    output_word = vectorizer.get_vocabulary()[predicted]\n",
        "    # Append to the current text\n",
        "    seed_text += \" \" + output_word\n",
        "print('Name:ROSELIN MARY JOVITA S     Register Number: 212222230122')\n",
        "print(seed_text)"
      ],
      "metadata": {
        "id": "VH6NnwsdKkSd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}